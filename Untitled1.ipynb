{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b291f9-2723-4a9d-aa54-45710ea0ce99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flash attention 2 is not installed\n",
      "ParlerTTSForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "ParlerTTSForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2816,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Config of the audio_encoder: <class 'transformers.models.dac.modeling_dac.DacModel'> is overwritten by shared audio_encoder config: DacConfig {\n",
      "  \"architectures\": [\n",
      "    \"DacModel\"\n",
      "  ],\n",
      "  \"codebook_dim\": 8,\n",
      "  \"codebook_loss_weight\": 1.0,\n",
      "  \"codebook_size\": 1024,\n",
      "  \"commitment_loss_weight\": 0.25,\n",
      "  \"decoder_hidden_size\": 1536,\n",
      "  \"downsampling_ratios\": [\n",
      "    2,\n",
      "    4,\n",
      "    8,\n",
      "    8\n",
      "  ],\n",
      "  \"encoder_hidden_size\": 64,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"hop_length\": 512,\n",
      "  \"model_type\": \"dac\",\n",
      "  \"n_codebooks\": 9,\n",
      "  \"quantizer_dropout\": 0.0,\n",
      "  \"sampling_rate\": 44100,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"upsampling_ratios\": [\n",
      "    8,\n",
      "    8,\n",
      "    4,\n",
      "    2\n",
      "  ]\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"ParlerTTSForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1025,\n",
      "  \"codebook_weights\": null,\n",
      "  \"cross_attention_implementation_strategy\": null,\n",
      "  \"delay_strategy\": \"delay\",\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 1024,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"parler_tts_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 9,\n",
      "  \"num_cross_attention_key_value_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 1024,\n",
      "  \"rope_embeddings\": false,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_fused_lm_heads\": true,\n",
      "  \"vocab_size\": 1088\n",
      "}\n",
      "\n",
      "Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2816,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Config of the audio_encoder: <class 'transformers.models.dac.modeling_dac.DacModel'> is overwritten by shared audio_encoder config: DacConfig {\n",
      "  \"architectures\": [\n",
      "    \"DacModel\"\n",
      "  ],\n",
      "  \"codebook_dim\": 8,\n",
      "  \"codebook_loss_weight\": 1.0,\n",
      "  \"codebook_size\": 1024,\n",
      "  \"commitment_loss_weight\": 0.25,\n",
      "  \"decoder_hidden_size\": 1536,\n",
      "  \"downsampling_ratios\": [\n",
      "    2,\n",
      "    4,\n",
      "    8,\n",
      "    8\n",
      "  ],\n",
      "  \"encoder_hidden_size\": 64,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"hop_length\": 512,\n",
      "  \"model_type\": \"dac\",\n",
      "  \"n_codebooks\": 9,\n",
      "  \"quantizer_dropout\": 0.0,\n",
      "  \"sampling_rate\": 44100,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"upsampling_ratios\": [\n",
      "    8,\n",
      "    8,\n",
      "    4,\n",
      "    2\n",
      "  ]\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"ParlerTTSForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1025,\n",
      "  \"codebook_weights\": null,\n",
      "  \"cross_attention_implementation_strategy\": null,\n",
      "  \"delay_strategy\": \"delay\",\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 1024,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"parler_tts_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 9,\n",
      "  \"num_cross_attention_key_value_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 1024,\n",
      "  \"rope_embeddings\": false,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_fused_lm_heads\": true,\n",
      "  \"vocab_size\": 1088\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import asyncio\n",
    "import queue\n",
    "import time\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "from transformers import AutoTokenizer\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.sambanova.ai/v1\",\n",
    "    api_key=\"4a81daa9-5f3d-409b-9f30-ebedb379219a\"\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(\"ai4bharat/indic-parler-tts\")\n",
    "MODEL_1 = ParlerTTSForConditionalGeneration.from_pretrained(\"ai4bharat/indic-parler-tts\").to(DEVICE)\n",
    "MODEL_2 = ParlerTTSForConditionalGeneration.from_pretrained(\"ai4bharat/indic-parler-tts\").to(DEVICE)\n",
    "\n",
    "DESC_TOKENIZER = AutoTokenizer.from_pretrained(MODEL_1.config.text_encoder._name_or_path)\n",
    "DESCRIPTION = (\"Rohit's voice is monotone yet slightly fast in delivery, with a very close recording that almost has no background noise.\")\n",
    "DESC_INPUTS = DESC_TOKENIZER(DESCRIPTION, return_tensors=\"pt\").to(DEVICE)\n",
    "DESC_INPUT_IDS = DESC_INPUTS.input_ids\n",
    "DESC_ATTN_MASK = DESC_INPUTS.attention_mask\n",
    "\n",
    "SAMPLING_RATE = MODEL_1.config.sampling_rate\n",
    "sd.default.latency = 'low'\n",
    "\n",
    "MAX_CHUNK_CHARS = 10000\n",
    "\n",
    "async def async_playback(queue1, queue2, done_event, latency_event):\n",
    "    next_from_queue1 = True\n",
    "    latency_measured = False\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            current_queue = queue1 if next_from_queue1 else queue2\n",
    "            try:\n",
    "                audio = await asyncio.wait_for(current_queue.get(), timeout=0.5)\n",
    "            except asyncio.TimeoutError:\n",
    "                current_queue = queue2 if next_from_queue1 else queue1\n",
    "                try:\n",
    "                    audio = await asyncio.wait_for(current_queue.get(), timeout=0.5)\n",
    "                except asyncio.TimeoutError:\n",
    "                    if done_event.is_set() and queue1.empty() and queue2.empty():\n",
    "                        break\n",
    "                    continue\n",
    "\n",
    "            if latency_event and not latency_measured:\n",
    "                latency_event.set()\n",
    "                latency_measured = True\n",
    "\n",
    "            sd.play(audio, samplerate=SAMPLING_RATE)\n",
    "            sd.wait()\n",
    "\n",
    "            next_from_queue1 = not (current_queue is queue1)\n",
    "\n",
    "        except asyncio.CancelledError:\n",
    "            break\n",
    "\n",
    "    print(\"Playback finished.\")\n",
    "\n",
    "def tts_worker(text_queue, audio_queue, model, loop):\n",
    "    async def put_audio(audio):\n",
    "        await audio_queue.put(audio)\n",
    "\n",
    "    while True:\n",
    "        text = text_queue.get()\n",
    "        if text is None:\n",
    "            break\n",
    "\n",
    "        prompt_inputs = TOKENIZER(text, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            speech_output = model.generate(\n",
    "                input_ids=DESC_INPUT_IDS,\n",
    "                attention_mask=DESC_ATTN_MASK,\n",
    "                prompt_input_ids=prompt_inputs.input_ids,\n",
    "                prompt_attention_mask=prompt_inputs.attention_mask\n",
    "            )\n",
    "        audio = speech_output.cpu().numpy().squeeze()\n",
    "        if audio.ndim > 1:\n",
    "            audio = audio.flatten()\n",
    "        audio = audio.astype(np.float32)\n",
    "        max_val = np.max(np.abs(audio))\n",
    "        if max_val > 0:\n",
    "            audio = audio / max_val\n",
    "\n",
    "        asyncio.run_coroutine_threadsafe(put_audio(audio), loop)\n",
    "\n",
    "def stream_llm_to_chunks(prompt, q1, q2, small_chunk=20, large_chunk=60):\n",
    "    buffer = \"\"\n",
    "    toggle = 0\n",
    "    max_queue_size=10\n",
    "    chunk_sizes = [small_chunk, large_chunk]\n",
    "    chunk_index = 0\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"Meta-Llama-3.2-3B-Instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a Hindi-only assistant. Keep responses short.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in response:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if hasattr(delta, \"content\") and delta.content:\n",
    "            buffer += delta.content\n",
    "            print(delta.content, end=\"\", flush=True)\n",
    "            current_chunk_size = chunk_sizes[chunk_index % 2]\n",
    "\n",
    "            while len(buffer) >= current_chunk_size:\n",
    "                chunk_text = buffer[:current_chunk_size].strip()\n",
    "                target_queue = q1 if toggle == 0 else q2\n",
    "\n",
    "                while target_queue.qsize() >= max_queue_size:\n",
    "                    time.sleep(0.01)\n",
    "\n",
    "                target_queue.put(chunk_text)\n",
    "                buffer = buffer[current_chunk_size:]\n",
    "                toggle = 1 - toggle\n",
    "                chunk_sizes[chunk_index % 2] = min(chunk_sizes[chunk_index % 2] * 2, MAX_CHUNK_CHARS)\n",
    "                chunk_index += 1\n",
    "    if buffer:\n",
    "        (q1 if toggle == 0 else q2).put(buffer.strip())\n",
    "\n",
    "    # time.sleep(1.0)  # Prevent premature shutdown\n",
    "    q1.put(None)\n",
    "    q2.put(None)\n",
    "\n",
    "def speak_from_prompt(prompt: str, small_chunk: int = 10, large_chunk: int = 70, measure_latency: bool = False):\n",
    "    Q1, Q2 = queue.Queue(), queue.Queue()\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    A1, A2 = asyncio.Queue(), asyncio.Queue()\n",
    "    done_event = threading.Event()\n",
    "    latency_event = threading.Event() if measure_latency else None\n",
    "\n",
    "    loop_thread = threading.Thread(target=loop.run_forever)\n",
    "    loop_thread.start()\n",
    "\n",
    "    tts_thread1 = threading.Thread(target=tts_worker, args=(Q1, A1, MODEL_1, loop))\n",
    "    tts_thread2 = threading.Thread(target=tts_worker, args=(Q2, A2, MODEL_2, loop))\n",
    "    tts_thread1.start()\n",
    "    tts_thread2.start()\n",
    "\n",
    "    start_time = time.time() if measure_latency else None\n",
    "    playback_future = asyncio.run_coroutine_threadsafe(\n",
    "        async_playback(A1, A2, done_event, latency_event), loop\n",
    "    )\n",
    "\n",
    "    stream_llm_to_chunks(prompt, Q1, Q2, small_chunk, large_chunk)\n",
    "    tts_thread1.join()\n",
    "    tts_thread2.join()\n",
    "\n",
    "    done_event.set()\n",
    "    playback_future.result()\n",
    "\n",
    "    loop.call_soon_threadsafe(loop.stop)\n",
    "    loop_thread.join()\n",
    "\n",
    "    if measure_latency and latency_event:\n",
    "        latency_event.wait()\n",
    "        latency = time.time() - start_time\n",
    "        print(f\"\\nSpeech synthesis complete.\\n⏱️ First audio latency: {latency:.2f} seconds\")\n",
    "    else:\n",
    "        print(\"\\nSpeech synthesis complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ffb423-a267-492e-890e-b8dd3e8a6015",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "एक छोटे से गाँव में एक लड़का रहता था। वह अपने दादाजी की दुकान में काम करता था। एक दिन, वह एक पुरानी किताब ढूंढता है जिसमें एक रहस्यमय पत्र है। उस पत्र में एक सुंदर लड़की का नाम लिखा है जो गाँव से 100 किलोमीटर दूर रहती है।\n",
      "\n",
      "लड़का उस पत्र को पढ़ता है और सोचता है कि वह उस लड़की को ढूंढने की कोशिश करेगा। वह उस पत्र के निर्देशों का पालन करता है और एक सुंदर यात्रा शुरू करता है।"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspeak_from_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgive me short story\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmall_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlarge_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasure_latency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 166\u001b[0m, in \u001b[0;36mspeak_from_prompt\u001b[0;34m(prompt, small_chunk, large_chunk, measure_latency)\u001b[0m\n\u001b[1;32m    163\u001b[0m tts_thread2\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    165\u001b[0m done_event\u001b[38;5;241m.\u001b[39mset()\n\u001b[0;32m--> 166\u001b[0m \u001b[43mplayback_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m loop\u001b[38;5;241m.\u001b[39mcall_soon_threadsafe(loop\u001b[38;5;241m.\u001b[39mstop)\n\u001b[1;32m    169\u001b[0m loop_thread\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8740:(snd_pcm_recover) underrun occurred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playback finished.\n"
     ]
    }
   ],
   "source": [
    "speak_from_prompt(\"give me short story\", small_chunk = 10, large_chunk = 20, measure_latency=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e0e1c-a06b-4c1f-8653-30280b113ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait until it says 'speak now'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-12 23:47:02.066] [ctranslate2] [thread 291848] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ speak nowनमस्ते! कैसे हैं आप?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:parler_tts.modeling_parler_tts:`prompt_attention_mask` is specified but `attention_mask` is not. A full `attention_mask` will be created. Make sure this is the intended behaviour.\n",
      "WARNING:parler_tts.modeling_parler_tts:`prompt_attention_mask` is specified but `attention_mask` is not. A full `attention_mask` will be created. Make sure this is the intended behaviour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ speak nowPlayback finished.\n",
      "\n",
      "Speech synthesis complete.\n",
      "Playback finished.म है सेवा।\n",
      "⠧ speak now\n",
      "Speech synthesis complete.\n",
      "⠋ speak nowing"
     ]
    }
   ],
   "source": [
    "from RealtimeSTT import AudioToTextRecorder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='multiprocessing')\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Wait until it says 'speak now'\")\n",
    "    recorder = AudioToTextRecorder(model=\"medium\",device=\"cpu\",allowed_latency_limit=30,language=\"en\",spinner=True)\n",
    "    while True:\n",
    "        recorder.text(speak_from_prompt)\n",
    "        # recorder.text(chat_completion_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b466376-5c60-4bdc-aa2a-e137b05d5edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f029c63007b643b49a8ed5bee676317d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bac0dd6f544c34a2598dc3cc0e88bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860ca49373e54991aaab875a5d781de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e5fe0172844c8e919fbd8037bb0846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb4a3c53be7468697f03fc3fc895991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/6.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f088b23056c641fe9e9b7a089ec018cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2816,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Config of the audio_encoder: <class 'parler_tts.dac_wrapper.modeling_dac.DACModel'> is overwritten by shared audio_encoder config: DACConfig {\n",
      "  \"architectures\": [\n",
      "    \"DACModel\"\n",
      "  ],\n",
      "  \"codebook_size\": 1024,\n",
      "  \"frame_rate\": 86,\n",
      "  \"latent_dim\": 1024,\n",
      "  \"model_bitrate\": 8,\n",
      "  \"model_type\": \"dac_on_the_hub\",\n",
      "  \"num_codebooks\": 9,\n",
      "  \"sampling_rate\": 44100,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"ParlerTTSForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1025,\n",
      "  \"codebook_weights\": null,\n",
      "  \"cross_attention_implementation_strategy\": null,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 1024,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"parler_tts_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 9,\n",
      "  \"num_cross_attention_key_value_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 1024,\n",
      "  \"rope_embeddings\": false,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_fused_lm_heads\": false,\n",
      "  \"vocab_size\": 1088\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5b3364e6184fe4bb487580db9210f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/265 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of length: 0.329 seconds\n",
      "(14507,)\n",
      "Sample of length: 0.4992 seconds\n",
      "(22016,)\n",
      "Sample of length: 0.4992 seconds\n",
      "(22016,)\n",
      "Sample of length: 0.4992 seconds\n",
      "(22016,)\n",
      "Sample of length: 0.1122 seconds\n",
      "(4949,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from parler_tts import ParlerTTSForConditionalGeneration, ParlerTTSStreamer\n",
    "from transformers import AutoTokenizer\n",
    "from threading import Thread\n",
    "\n",
    "torch_device = \"cuda:0\" # Use \"mps\" for Mac \n",
    "torch_dtype = torch.bfloat16\n",
    "model_name = \"parler-tts/parler-tts-mini-v1\"\n",
    "\n",
    "# need to set padding max length\n",
    "max_length = 50\n",
    "\n",
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    ").to(torch_device, dtype=torch_dtype)\n",
    "\n",
    "sampling_rate = model.audio_encoder.config.sampling_rate\n",
    "frame_rate = model.audio_encoder.config.frame_rate\n",
    "\n",
    "def generate(text, description, play_steps_in_s=0.5):\n",
    "  play_steps = int(frame_rate * play_steps_in_s)\n",
    "  streamer = ParlerTTSStreamer(model, device=torch_device, play_steps=play_steps)\n",
    "  # tokenization\n",
    "  inputs = tokenizer(description, return_tensors=\"pt\").to(torch_device)\n",
    "  prompt = tokenizer(text, return_tensors=\"pt\").to(torch_device)\n",
    "  # create generation kwargs\n",
    "  generation_kwargs = dict(\n",
    "    input_ids=inputs.input_ids,\n",
    "    prompt_input_ids=prompt.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    prompt_attention_mask=prompt.attention_mask,\n",
    "    streamer=streamer,\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    "    min_new_tokens=10,\n",
    "  )\n",
    "  # initialize Thread\n",
    "  thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "  thread.start()\n",
    "  # iterate over chunks of audio\n",
    "  for new_audio in streamer:\n",
    "    if new_audio.shape[0] == 0:\n",
    "      break\n",
    "    print(f\"Sample of length: {round(new_audio.shape[0] / sampling_rate, 4)} seconds\")\n",
    "    yield sampling_rate, new_audio\n",
    "\n",
    "\n",
    "# now you can do\n",
    "text = \"This is a test of the streamer class\"\n",
    "description = \"Jon's talking really fast.\"\n",
    "\n",
    "chunk_size_in_s = 0.5\n",
    "\n",
    "for (sampling_rate, audio_chunk) in generate(text, description, chunk_size_in_s):\n",
    "  # You can do everything that you need with the chunk now\n",
    "  # For example: stream it, save it, play it.\n",
    "  print(audio_chunk.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ec4309-cdbd-444a-8f36-265142b02131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00,  2.75it/s]\u001b[0m\u001b[0m\n",
      "Wait until it says 'speak now'\u001b[0m\n",
      "ALSA lib pcm_dsnoop.c:567:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_a52.c:1001:(_snd_pcm_a52_open) a52 is only for playback\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.30 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "जी रो क्रोसीं रे नेassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠼\u001b[0m speak now\u001b[0mकहना \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mचाहते \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहैं?\u001b[0m0m\u001b[0m\u001b[0mहूँ। \u001b[0m\u001b[0mआप \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mक्या \u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.20 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "विएडियावेassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠇\u001b[0m speak now\u001b[0mसकते \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहैं।\u001b[0mलोगों \u001b[0m\u001b[0m\u001b[0m\u001b[0mके \u001b[0m\u001b[0m\u001b[0m\u001b[0mसाथ \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mसाझा \u001b[0m\u001b[0mकर \u001b[0m\u001b[0m\u001b[0m\u001b[0m[0m\u001b[0mm\u001b[0m[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.30 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "त्रेशोल अनाजी गोशिंग ओकेassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠼\u001b[0m speak now\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mओके \u001b[0m\u001b[0m\u001b[0m\u001b[0mकौन \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहै?\u001b[0mm\u001b[0mत्रेशोल \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mअनाजी \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mगोशिंग \u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.75 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "आप दे आवा पर दिप्लेनिंग बेज़। आप दे आवा पर दिप्लेनिंग बेज़। आप दे आवा पर दिप्लेनिंग बेज़।assistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠧\u001b[0m speak now\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mमहत्वपूर्ण \u001b[0m\u001b[0m\u001b[0m\u001b[0mघटक \u001b[0m\u001b[0mहै।ान \u001b[0m\u001b[0m\u001b[0m\u001b[0mकरने \u001b[0m\u001b[0m\u001b[0m\u001b[0mके \u001b[0m\u001b[0m\u001b[0m\u001b[0mलिए \u001b[0m\u001b[0mएक \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mानों \u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36m⠇\u001b[0m speak now\u001b[0mबेज़ \u001b[0m\u001b[0m\u001b[0m\u001b[0mकी \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mकार्यशीलता \u001b[0m\u001b[0mइस \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mप्रकार \u001b[0m\u001b[0m\u001b[0m\u001b[0mहै:\n",
      "\u001b[1m\u001b[36m⠋\u001b[0m speak now\u001b[0mजाना।[0m\u001b[0m\u001b[0m1. \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mविमान \u001b[0m\u001b[0m\u001b[0m\u001b[0mको \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mउंचाई \u001b[0m\u001b[0mपर \u001b[0m\u001b[0m\u001b[0m\u001b[0mले \u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0mके \u001b[0m\u001b[0m\u001b[0m\u001b[0mलिए।विमान \u001b[0m\u001b[0m\u001b[0m\u001b[0mको \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mस्थिर \u001b[0m\u001b[0m\u001b[0m\u001b[0mरखने \u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠹\u001b[0m speak now\u001b[0mनियंत्रित \u001b[0m\u001b[0m\u001b[0m\u001b[0mकरने \u001b[0m\u001b[0m\u001b[0m\u001b[0mके \u001b[0m\u001b[0m\u001b[0m\u001b[0mलिए।0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠼\u001b[0m speak now\u001b[0m\u001b[0m\u001b[0mलिए।\u001b[0m\u001b[0m\u001b[0mसुरक्षित \u001b[0m\u001b[0m\u001b[0m\u001b[0mरूप \u001b[0m\u001b[0m\u001b[0m\u001b[0mसे \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mउड़ाने \u001b[0m\u001b[0m\u001b[0m\u001b[0mके \u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36m⠧\u001b[0m speak now\u001b[0m\u001b[0m\u001b[0mहै।\u001b[0mm\u001b[0m\u001b[0mउड़ाने \u001b[0m\u001b[0m\u001b[0m\u001b[0mके \u001b[0m\u001b[0m\u001b[0m\u001b[0mलिए \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mकिया \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mजाता \u001b[0m\u001b[0m\u001b[0m\u001b[0m0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.25 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "से लिए रोवेग.assistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠹\u001b[0m speak now\u001b[0mक्या \u001b[0m\u001b[0m\u001b[0m\u001b[0mपूछ \u001b[0m\u001b[0m\u001b[0m\u001b[0mरहे \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहैं?\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.30 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "मुझे शेक्सी वज्टूassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠴\u001b[0m recording\u001b[0m\u001b[0m\u001b[0mजाती \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहै।\u001b[0mपी \u001b[0m\u001b[0m\u001b[0m\u001b[0mm \u001b[0m\u001b[0m[0m\u001b[0m\u001b[0mदूध, \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mचीनी, \u001b[0m\u001b[0mऔर \u001b[0m\u001b[0m\u001b[0m\u001b[0m[0mहै, \u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.30 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "लोगो कहीरी चे हूँ गुदूब बना दिनाassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠸\u001b[0m speak now\u001b[0mमदद \u001b[0m\u001b[0m\u001b[0m\u001b[0mनहीं \u001b[0m\u001b[0mकर \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mसकता।\u001b[0mी \u001b[0m\u001b[0m\u001b[0m\u001b[0mभी \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mबातचीत \u001b[0m\u001b[0m\u001b[0m\u001b[0mमें \u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.25 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "ही नहाँ रोहे हाँ को रहा हैassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠴\u001b[0m speak now\u001b[0m\u001b[0m\u001b[0mआवश्यकता \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहै?\u001b[0m0m\u001b[0mतुम्हें \u001b[0m\u001b[0m\u001b[0m\u001b[0mकुछ \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mसहायता \u001b[0m\u001b[0m\u001b[0m\u001b[0mकी \u001b[0m\u001b[0m\u001b[0m\u001b[0mm\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.60 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "अचो दिनू मने आत्यारा आउट्पू दुनदा जत्या पामिन्डू अवे हुं करो अनुप्याassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠧\u001b[0m recording\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहोगी।\u001b[0mm\u001b[0m\u001b[0m\u001b[0mकरनी \u001b[0m\u001b[0m\u001b[0m\u001b[0mmm\u001b[0mm\u001b[0m[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mलेकिन \u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.33 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "आरू आवस को जिजो है न जिबी दिफ्याassistant\n",
      "\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.48 seconds\u001b[0mm\u001b[0m\u001b[0m\u001b[0m0m\u001b[0m0m\u001b[0mm\u001b[0m\u001b[0m\u001b[0mआवस \u001b[0m\u001b[0m\u001b[0m\u001b[0mको \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "जिपी देना मारे आपको लिए भायो हो रहा है।assistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠼\u001b[0m speak now\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहोता \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mक्या \u001b[0m\u001b[0m\u001b[0m\u001b[0mहै।\u001b[0m0mसंघर्ष \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mकरना \u001b[0m\u001b[0mहैं? \u001b[0m\u001b[0m\u001b[0m\u001b[0mं \u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠧\u001b[0m recording\u001b[0m\u001b[0m\u001b[0mहै?\u001b[0mm\u001b[0m\u001b[0m\u001b[0mसही \u001b[0m\u001b[0m\u001b[0m\u001b[0mनहीं \u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.41 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "यामा भे लोगार्थी लोकिंग में के लिए.assistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠸\u001b[0m speak now\u001b[0m\u001b[0m\u001b[0mजैसे \u001b[0m\u001b[0m\u001b[0m\u001b[0mकि:0m\u001b[0m\u001b[0mलिए \u001b[0m\u001b[0mकई \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mविकल्प \u001b[0m\u001b[0m\u001b[0m\u001b[0mहो \u001b[0m\u001b[0m\u001b[0m\u001b[0mसकते \u001b[0m\u001b[0m\u001b[0m\u001b[0mहैं, \u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36m⠇\u001b[0m recording\u001b[0mमें \u001b[0m\u001b[0mमदद \u001b[0m\u001b[0mकर \u001b[0m\u001b[0m\u001b[0m\u001b[0mसकते \u001b[0m\u001b[0mहैं।[0mm[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠼\u001b[0m recording\u001b[0mमें \u001b[0m\u001b[0mमदद \u001b[0m\u001b[0mकर \u001b[0m\u001b[0m\u001b[0m\u001b[0mसकते \u001b[0m\u001b[0mहैं।m[0m\n",
      "\u001b[1m\u001b[36m⠋\u001b[0m recording\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mप्रदान \u001b[0m\u001b[0m\u001b[0m\u001b[0mकरते \u001b[0m\u001b[0mहैं।m\u001b[0mm\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.35 seconds\u001b[0m[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0mइसका \u001b[0m\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "आजी एक प्रोब्लेम आदे है।assistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠴\u001b[0m speak now\u001b[0m\u001b[0m\u001b[0mकरने \u001b[0m\u001b[0m\u001b[0m\u001b[0mकरेगा।\u001b[0mताओं \u001b[0m\u001b[0m\u001b[0m\u001b[0mपर \u001b[0m\u001b[0mमैं \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mआपकी \u001b[0m\u001b[0mनिर्भर \u001b[0m\u001b[0mमदद \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mका \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mप्रयास \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mकरूंगा।\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.48 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "तो में इन्हें बीजा दुचे डेमो जो दो तो इन्हें दुचेassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m recording\u001b[0mजा \u001b[0m\u001b[0m\u001b[0m\u001b[0mसकते \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहैं।\u001b[0m\u001b[0m\u001b[0m0m\u001b[0m\u001b[0m\u001b[0mनाम \u001b[0m\u001b[0m\u001b[0m\u001b[0mदर्ज \u001b[0m\u001b[0m\u001b[0m\u001b[0mकरके \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.43 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "तो मैं जुनो कोड कोमेंट आउट करें इन्ने चालो भाई दी थोassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m recording\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहैं?\u001b[0mm\u001b[0m\u001b[0m\u001b[0mचाहते \u001b[0m\u001b[0m\u001b[0m\u001b[0mm\u001b[0m0mपकी \u001b[0m\u001b[0mमदद \u001b[0m\u001b[0mकर \u001b[0m\u001b[0m\u001b[0m\u001b[0mसकता \u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.40 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "ते तू ट्रांस्परान से नहीं आप तो नहीं भुभुभुassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠦\u001b[0m speak now\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mतैयार \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहूँ।\u001b[0m0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mप्रदान \u001b[0m\u001b[0m\u001b[0m\u001b[0mकरने \u001b[0m\u001b[0m\u001b[0m\u001b[0mके \u001b[0m\u001b[0m\u001b[0m\u001b[0mलिए \u001b[0m\u001b[0mm\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.40 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "ये मारे ही प्रोब्लेमा अथे तो के लिए हैं।assistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠸\u001b[0m recording\u001b[0mप्रयास \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mकरूँगा।\u001b[0m[0m0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहै \u001b[0m\u001b[0mऔर \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mतुम्हें \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.65 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "मॉल्टी त्रेडिंग करी हैं नहीं और मॉल्टी त्रेडिंग ती वेब्साइट स्क्रेब करा रहा रहा रहाassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠸\u001b[0m recording\u001b[0mसकती \u001b[0m\u001b[0mहैं।मस्याएं \u001b[0m\u001b[0m\u001b[0m\u001b[0mहो \u001b[0m\u001b[0m\u001b[0m\u001b[0m0m\u001b[0mmजानना \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mमहत्वपूर्ण \u001b[0m\u001b[0m\u001b[0m\u001b[0mहै \u001b[0m\u001b[0m\u001b[0m\u001b[0mकि \u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36m⠋\u001b[0m recording\u001b[0m\u001b[0m\u001b[0mबरतें।0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mसावधानी \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mm\n",
      "\n",
      "\u001b[1m\u001b[36m⠋\u001b[0m recording\u001b[0mकरते \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mहैं।\u001b[0m[0mपालन \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mModel medium completed transcription in 0.61 seconds\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m speak now\u001b[0msystem\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 12 May 2025\n",
      "\n",
      "You are a helpful voice AI assistant. Keep your answer short and don't use abbreviation and special tokens. Give your reply in hindi language only.user\n",
      "\n",
      "इनिश्यल एक वेप्साइट ने लिंक होए इमाँ ती मॉल्टिपल पेट पर जाए ने स्क्रेप्ट करेassistant\n",
      "\n",
      "\u001b[1m\u001b[36m⠸\u001b[0m speak now\u001b[0m\u001b[0m\u001b[0mआपको \u001b[0m\u001b[0mएक \u001b[0m\u001b[0m\u001b[0m\u001b[0mउदाहरण \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mदूंगा।ने \u001b[0m\u001b[0m\u001b[0m\u001b[0mके \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mलिए, \u001b[0m\u001b[0m\u001b[0m\u001b[0mमैं \u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36m⠹\u001b[0m recording\u001b[0m\u001b[0m\u001b[0mहै:ोगी \u001b[0m\u001b[0m\u001b[0m\u001b[0mहो \u001b[0m\u001b[0m\u001b[0m\u001b[0mसकती \u001b[0m\u001b[0m0m\u001b[0m[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mवेप्साइट \u001b[0m\u001b[0m\u001b[0m\u001b[0mहै \u001b[0m\u001b[0m\u001b[0m\u001b[0mजो \u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m```javascript\n",
      "\u001b[1m\u001b[36m⠼\u001b[0m recording\u001b[0m\u001b[0m\u001b[0mकी \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mजानकारीट \u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠴\u001b[0m recording\u001b[0mconst \u001b[0m\u001b[0minitial \u001b[0m\u001b[0m= {\n",
      "\u001b[1m\u001b[36m⠦\u001b[0m recording\u001b[0mname: \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m'Inishyel',\n",
      "\u001b[1m\u001b[36m⠧\u001b[0m recording\u001b[0m \u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mage: \u001b[0m\u001b[0m\u001b[0m\u001b[0m25,\n",
      "\u001b[1m\u001b[36m⠏\u001b[0m recording\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m'वेप्साइट'occupation: \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m};\n",
      "\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m recording\u001b[0mकी \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mजानकारी[0mती \u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠹\u001b[0m recording\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mimanTee \u001b[0m\u001b[0m= {\n",
      "\u001b[1m\u001b[36m⠼\u001b[0m recording\u001b[0mTee',\u001b[0m\u001b[0m\u001b[0mname: \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m'Iman \u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠴\u001b[0m recording\u001b[0m30,[0mage: \u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠦\u001b[0m recording\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m'डॉक्टर'0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m};\n",
      "\n",
      "\u001b[1m\u001b[36m⠋\u001b[0m recording\u001b[0m\u001b[0m\u001b[0mस्क्रिप्ट0mलिए \u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mm\u001b[0m\n",
      "\u001b[1m\u001b[36m⠙\u001b[0m recording\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mgoToMultiplePets() {\n",
      "\u001b[1m\u001b[36m⠴\u001b[0m recording^C0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mमॉल्टिपल \u001b[0m\u001b[0m\u001b[0m\u001b[0mन \u001b[0m\u001b[0m\u001b[0m\u001b[0mती \u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[91mRealtimeSTT shutting down\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m⠦\u001b[0m recordingTraceback (most recent call last):\n",
      "  File \"/media/irlab/ba5a20df-2f59-4a88-b4ad-08a3df254e15/Parth/Voice/ASR.py\", line 232, in <module>\n",
      "    recorder.text(chat_completion_llama)\n",
      "  File \"/home/irlab/.pyenv/versions/pyvoice/lib/python3.10/site-packages/RealtimeSTT/audio_recorder.py\", line 1658, in text\n",
      "    self.wait_audio()\n",
      "  File \"/home/irlab/.pyenv/versions/pyvoice/lib/python3.10/site-packages/RealtimeSTT/audio_recorder.py\", line 1433, in wait_audio\n",
      "    if (self.stop_recording_event.wait(timeout=0.02)):\n",
      "  File \"/home/irlab/.pyenv/versions/3.10.13/lib/python3.10/threading.py\", line 607, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/home/irlab/.pyenv/versions/3.10.13/lib/python3.10/threading.py\", line 324, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\u001b[0m\u001b[0m\u001b[0mरहा \u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python ASR.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df82610-1440-43ab-923b-8fae8cd9a27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
